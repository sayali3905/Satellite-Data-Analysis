# -*- coding: utf-8 -*-
"""CloudRemoval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_8cBfnTQ-68NO3hLpRjbGa1YEzOzLXoF
"""

!pip install rasterio

from google.colab import drive
drive.mount('/content/drive')

cd '/content/drive/MyDrive/RnD_Datasets'

import zipfile
import io
import os
from google.colab import drive
from google.colab import files

input_dir = 'Alamatti_data'
outputfp = open('op', 'w')
band_names = []
for file_name in os.listdir(input_dir):
    if file_name.endswith('.zip'):
        with zipfile.ZipFile(os.path.join(input_dir, file_name), 'r') as zip_file:
            for inner_file_name in zip_file.namelist():
                if inner_file_name.endswith('B03_10m.jp2') or inner_file_name.endswith('B08_10m.jp2'):
                    with io.BytesIO(zip_file.read(inner_file_name)) as mem_file:
                      #print("hello")
                      with open(inner_file_name[-34:], 'wb') as output_file:
                        output_file.write(mem_file.getbuffer())
                        band_names.append(inner_file_name)
                    print(inner_file_name)
                    break

import rasterio
import matplotlib.pyplot as plt

with rasterio.open('T43QEU_20220923T051649_B03_10m.jp2') as src:
    meta = src.meta
    # If cloud mask data is available, read it in
    cloud_mask = src.read_masks(1)

# Read the image into a numpy array
with rasterio.open('T43QEU_20220923T051649_B03_10m.jp2') as src:
    img = src.read(1)
#print(img)
print(img.shape)
fig, ax = plt.subplots()
ax.imshow(img)  # Assumes a single band image
plt.show()

import rasterio
import matplotlib.pyplot as plt

with rasterio.open('T43QEU_20221222T052229_B03_10m.jp2') as src:
    meta = src.meta
    # If cloud mask data is available, read it in
    #cloud_mask = src.read_masks(1)

# Read the image into a numpy array
with rasterio.open('T43QEU_20221222T052229_B03_10m.jp2') as src:
    img_main = src.read(1)
print(img_main)
print(img_main.shape)
fig, ax = plt.subplots()
ax.imshow(img_main)  # Assumes a single band image
plt.show()

import rasterio
import numpy as np
from rasterio.plot import show

def mask_clouds(input_file):
    # Load the green band image
    with rasterio.open(input_file) as src:
        green = src.read(1)

    # Set the threshold value for cloud detection
    threshold = 6000

    # Create a boolean mask where True indicates cloud pixels
    clouds = green > threshold

    # Invert the mask so that True indicates clear pixels
    clear = np.invert(clouds)

    # Create a new image where cloud pixels are masked out
    with rasterio.open(input_file) as src:
        out_meta = src.meta.copy()
        out_meta.update({"count": 1})
        with rasterio.open("masked.tif", "w", **out_meta) as dst:
            masked = src.read(1, masked=True)
            masked[clouds] = 0
            dst.write(masked, 1)
    print(masked.shape)
    # Display the masked image
    with rasterio.open("masked.tif") as src:
        show(src.read(1))

    return masked

# Example usage
input_file = "T43QEU_20220923T051649_B03_10m.jp2"
masked = mask_clouds(input_file)
#print(masked)

patch_size = 28

# Compute the number of patches in each dimension
num_patches_x = masked.shape[0] // patch_size
num_patches_y = masked.shape[1] // patch_size
#print(num_patches_x, num_patches_y)

# Initialize the patches array
patches = np.zeros((num_patches_x * num_patches_y, patch_size, patch_size))
#print(patches.shape)

# Loop over each patch and extract it from the input image
for i in range(num_patches_x):
    for j in range(num_patches_y):
        patch = masked[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]
        patches[i*num_patches_y+j, :, :] = patch

# Print the shape of the patches array
print(patches.shape)

patch_size = 28

# Compute the number of patches in each dimension
num_patches_x = img_main.shape[0] // patch_size
num_patches_y = img_main.shape[1] // patch_size
#print(num_patches_x, num_patches_y)

# Initialize the patches array
discri_data = np.zeros((num_patches_x * num_patches_y, patch_size, patch_size))
#print(patches.shape)

# Loop over each patch and extract it from the input image
for i in range(num_patches_x):
    for j in range(num_patches_y):
        patch = img_main[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]
        discri_data[i*num_patches_y+j, :, :] = patch
#print(discri_data)
print(discri_data.shape)

def define_discriminator(in_shape=(28,28,1)):
	model = Sequential()
	model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))
	model.add(LeakyReLU(alpha=0.2))
	model.add(Dropout(0.4))
	model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))
	model.add(LeakyReLU(alpha=0.2))
	model.add(Dropout(0.4))
	model.add(Flatten())
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = Adam(lr=0.0002, beta_1=0.5)
	model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
	return model

def define_generator(latent_dim):
	model = Sequential()
	# foundation for 7x7 image
	n_nodes = 128 * 7 * 7
	model.add(Dense(n_nodes, input_dim=latent_dim))
	model.add(LeakyReLU(alpha=0.2))
	model.add(Reshape((7, 7, 128)))
	# upsample to 14x14
	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
	model.add(LeakyReLU(alpha=0.2))
	# upsample to 28x28
	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
	model.add(LeakyReLU(alpha=0.2))
	model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))
	return model

# define the combined generator and discriminator model, for updating the generator
def define_gan(g_model, d_model):
	# make weights in the discriminator not trainable
	d_model.trainable = False
	# connect them
	model = Sequential()
	# add generator
	model.add(g_model)
	model.add(d_model)
	# add the discriminator
	# compile model
	opt = Adam(lr=0.0002, beta_1=0.5)
	model.compile(loss='binary_crossentropy', optimizer=opt)
	return model

def load_real_samples(patches):
	# load mnist dataset
	# expand to 3d, e.g. add channels dimension
	X = expand_dims(patches, axis=-1)
	# convert from unsigned ints to floats
	X = X.astype('float32')
	# scale from [0,255] to [0,1]
	X = (np.max(X) - X)/(np.max(X)-np.min(X))
	return X

# select real samples
def generate_real_samples(dataset, n_samples):
	# choose random instances
	ix = randint(0, dataset.shape[0], n_samples)
	# retrieve selected images
	X = dataset[ix]
	# generate 'real' class labels (1)
	y = ones((n_samples, 1))
	return X, y

# generate points in latent space as input for the generator
def generate_latent_points(latent_dim, n_samples):
	# generate points in the latent space
	x_input = randn(latent_dim * n_samples)
	# reshape into a batch of inputs for the network
	x_input = x_input.reshape(n_samples, latent_dim)
	return x_input

# use the generator to generate n fake examples, with class labels
def generate_fake_samples(g_model, latent_dim, n_samples):
	# generate points in latent space
	x_input = generate_latent_points(latent_dim, n_samples)
	# predict outputs
	X = g_model.predict(x_input)
	# create 'fake' class labels (0)
	y = zeros((n_samples, 1))
	return X, y

fake = []
real = []
def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):
	# prepare real samples
  X_real, y_real = generate_real_samples(dataset, n_samples)
	# evaluate discriminator on real examples
  _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)
	# prepare fake examples
  x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)
	# evaluate discriminator on fake examples
  _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)
	# summarize discriminator performance
  print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))
	# save plot
  real.append(acc_real)
  fake.append(acc_fake)
	#plt.plot(x_fake, epoch)

def plot_history(d_hist, g_hist):
				# plot loss
    pyplot.subplot(2, 1, 1)
    pyplot.plot(d_hist, label='discriminator_loss', color='r')
    pyplot.plot(g_hist, label='generator_loss', color='b')
    pyplot.xlabel('Number of epochs')
    pyplot.ylabel("loss")
    pyplot.legend()

def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=20, n_batch=256):
  bat_per_epo = int(dataset.shape[0] / n_batch)
  half_batch = int(n_batch / 2)
	# manually enumerate epochs
  for i in range(21, 31):
		# enumerate batches over the training set
    for j in range(8):
			# get randomly selected 'real' samples
      X_real, y_real = generate_real_samples(dataset, half_batch)
			# generate 'fake' examples
      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)
			# create training set for the discriminator
      X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))
			# update discriminator model weights
      d_loss, _ = d_model.train_on_batch(X, y)
			# prepare points in latent space as input for the generator
      X_gan = generate_latent_points(latent_dim, n_batch)
			# create inverted labels for the fake samples
      y_gan = ones((n_batch, 1))
			# update the generator via the discriminator's error
      g_loss = gan_model.train_on_batch(X_gan, y_gan)
			# summarize loss on this batch
      print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))
    d_hist.append(d_loss)
    g_hist.append(g_loss)
    if (i+1) % 5 == 0:
      summarize_performance(i, g_model, d_model, dataset, latent_dim)
      #plot_history(d_hist, g_hist)

from numpy import expand_dims
from numpy import ones
from numpy import zeros
from numpy.random import rand
from numpy.random import randint
from keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv2D
from keras.layers import Flatten
from keras.layers import Dropout
from keras.layers import LeakyReLU
from numpy.random import randn
from keras.layers import Reshape
from keras.layers import Conv2DTranspose
from matplotlib import pyplot
from numpy import hstack
import pandas as pd
import random
import numpy as np
import matplotlib.pyplot as plt
from numpy import vstack
from keras.datasets.mnist import load_data
from keras.optimizers import Adam

d_model = define_discriminator()
# load image data
dataset = load_real_samples(patches)
#print(dataset.shape)
latent_dim = 100
# generate samples
n_samples = 25
#X, _ = generate_fake_samples_1(model, latent_dim, n_samples)
g_model = define_generator(latent_dim)
#g_model.summary()
# create the gan
gan_model = define_gan(g_model, d_model)
# summarize gan model
gan_model.summary()
train(g_model, d_model, gan_model, dataset, latent_dim)

plot_history(d_hist, g_hist)

#X, y = generate_fake_samples(g_model, latent_dim, 1000)
latent_points = generate_latent_points(100, 1000)
#print(X[1].shape)
output = g_model.predict(latent_points)

print(output)
print(ouput.shape)